{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDYnD_yh-skJ"
   },
   "source": [
    "# Classifieur de Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bhgi21K2-nFa"
   },
   "source": [
    "lien du brief : https://simplonline.co/briefs/97a4822f-8af0-4607-86b3-83dbfdd05d5e "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptif de Simplonline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contexte :\n",
    "\n",
    "Concevoir un classifieur de détection automatique de SPAM.\n",
    "\n",
    "La collection SMS Spam est un ensemble de messages SMS marqués qui ont été collectés pour la recherche sur les SMS Spam. Elle contient un ensemble de messages SMS en anglais de 5 574 messages, étiquetés selon qu'ils sont ham (légitimes) ou spam.\n",
    "Je vous encourage à vous documenter sur les caractéristiques type des spam et de développer votre stratégie de préparation des données dans ce sens.\n",
    "\n",
    "En tant que développeur IA, voici les missions :\n",
    "- Analyse du besoin\n",
    "- Construction d'un pipeline de ML\n",
    "- Prétraitement des données\n",
    "- Entrainement, fine tuning, validation et sélection d'un modèle de classification\n",
    "\n",
    "Les fichiers contiennent un message par ligne. Chaque ligne est composée de deux colonnes : v1 contient le label (ham ou spam) et v2 contient le texte brut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "liens :\n",
    "\n",
    "dataset : https://github.com/remijul/dataset/blob/master/SMSSpamCollection\n",
    "\n",
    "informations : https://archive.ics.uci.edu/dataset/228/sms+spam+collection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critères de performance :\n",
    "\n",
    "- compréhension du jeux de données\n",
    "- capacité à préparer les données\n",
    "- performance des modèles de prédiction\n",
    "- capacité à apporter une solution dans le temps imparti\n",
    "- rédaction du notebook\n",
    "- qualité du synthèse du travail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Livrables :\n",
    "\n",
    "* créer un/des notebook reproductible, commenté, expliqué (IMPORTANT !)\n",
    "* créer un repo git et un espace sur github/gitlab pour le projet (code refactorisé)\n",
    "* faire une présentation (slides) qui explique votre démarche et les résultats obtenus avec :\n",
    "- un document technique qui explique l'outil\n",
    "- la procédure suivie pour préparer les données et le preprocessing\n",
    "- la procédure suivie pour trouver un modèle adapté\n",
    "- le modèle d'IA sélectionné\n",
    "\n",
    "BONUS :\n",
    "* Application streamlit qui fait de la prédiction en temps réel d'un message déposé par l'utilisateur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse du contexte "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D'où viennent les données : Par qui ? Pour quoi ? Comment ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMS Spam Collection est un ensemble public de messages étiquetés par SMS qui ont été collectés pour la recherche sur le spam pour les téléphones portables.\n",
    "\n",
    "##### Instances = 5574\n",
    "\n",
    "##### Informations supplémentaires\n",
    "\n",
    "Ce corpus a été collecté à partir de sources de recherche gratuites ou gratuites sur Internet:\n",
    "\n",
    "Une collection de 425 messages de spam par SMS a été extraite manuellement du site Web de Grumbletext. Il s'agit d'un forum britannique dans lequel les utilisateurs de téléphones portables font des déclarations publiques sur les SMS spam, la plupart d'entre eux sans signaler le message de spam reçu. L'identification du texte des messages de spam dans les revendications est une tâche très difficile et longue, et il a consisté à numériser soigneusement des centaines de pages Web. Le site Web de Grumbletext est le suivant: http://www.grumbletext.co.uk/.\n",
    "Un sous-ensemble de 3 375 SMS choisis au hasard par jambon du NUS SMS Corpus (NSC), qui est un ensemble de données d'environ 10 000 messages légitimes collectés pour la recherche au Département de l'informatique de l'Université nationale de Singapour. Les messages proviennent en grande partie de Singapouriens et principalement d'étudiants fréquentant l'Université. Ces messages ont été recueillis auprès de volontaires qui ont été informés que leurs contributions allaient être rendues publiques. Le NUS SMS Corpus est disponible à l'adresse suivante: http://www.comp.nus.edu.sg/.rpnlpir/downloads/corpora/smsCorpus/.\n",
    "Une liste de 450 SMS de type jambon collectés sur la thèse de doctorat de Caroline Tag disponible à l'adresse http://etheses.bham.ac.uk/253/1/Tagg09PhD.pdf.\n",
    "Enfin, nous avons incorporé le SMS Spam Corpus v.0.1 Big. Il contient 1 002 messages de mja SMS et 322 messages de spam et il est disponible en public à l'adresse suivante: http://www.esp.uem.es/jmgomez/smsspamcorpus/. Ce corpus a été utilisé dans les recherches universitaires suivantes:\n",
    "\n",
    "1 G-3mez Hidalgo, J.M., Cajigas Bringas, G., Puertas Sanz, E., Carrero Garcia, F. Filtration par SMS basée sur le contenu. Actes du Colloque 2006 de l'ACM sur l'ingénierie des documents (ACM DOCENG'06), Amsterdam (Pays-Bas), 10-13, 2006.\n",
    "\n",
    "Cormack, G. V., G-3mez Hidalgo, J. M., et Puertas Sonz, E. Ingénierie technique pour filtrage de spam mobile (SMS).  Actes de la trentième Conférence internationale annuelle de la CMA sur la recherche et le développement dans la recherche et le développement dans le domaine de la recherche et de l'information (ACM SIGIR'07), New York, NY, 871-872, 2007.\n",
    "\n",
    "3 Cormack, G. V., G-3mez Hidalgo, J. M., et Puertas Sonz, E. Filtration de spam pour les messages courts. Actes de la seizième Conférence de l'ACM sur la gestion de l'information et des connaissances (ACM CIKM'07). Lisbonne, Portugal, 313-320, 2007.\n",
    "\n",
    "##### Des valeurs manquantes ont-elles été des valeurs?\n",
    "\n",
    "Non\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A quoi on reconnait un Spam ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Généralement, les messages malveillants sont envoyés à destination d'un grand nombre de cibles, ils ne sont pas ou peu personnalisés.\n",
    "\n",
    "- Le message évoque un dossier, une facture, un thème qui ne vous parle pas ? Il s'agit certainement d'un courriel malveillant.\n",
    "\n",
    "(source : https://www.economie.gouv.fr/entreprises/comment-lutter-contre-spams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment faire pour reconnaitre un Spam à partir d'un texte ? (hypotèse de travail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rechercher dans le texte brut :\n",
    "- des mots clé comme : 'URGENT!', 'Quiz!', 'YOU!', 'Txt:', 'now!', 'Call ', 'Win', 'WINNER', '!!', \n",
    "- des montions à de l'argent\n",
    "- des numéros de téléphone\n",
    "- des e-mails\n",
    "- des liens\n",
    "- utilisation de mot en majuscule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, os\n",
    "from sklearn.naive_bayes import BernoulliNB, CategoricalNB, ComplementNB, GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC, SVR, LinearSVC, LinearSVR, NuSVC, NuSVR, OneClassSVM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, OrdinalEncoder, StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOB7I9fDarj7"
   },
   "source": [
    "## Amélioration du prétraitement et du model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "refaire préproces et modelisation avec une pipeline pour être plus éfficace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "préparation du netoyage des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taitement_na_duplic (df) :\n",
    "    \"\"\"\n",
    "    entrée : un data frame\n",
    "    sortie : 2 data frame = 'principal' et 'na'\n",
    "    ---------------------------\n",
    "    \"\"\"\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna()\n",
    "    df.rename(columns={0:'classification', '0':'classification'}, inplace=True)\n",
    "    df.rename(columns={1:'sms', '1':'sms'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "préparation de l'encodage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mot_cle_posible (sms) :\n",
    "    \"\"\"\n",
    "    entrée : chaine de caractère\n",
    "    sortie : boolean\n",
    "    ---------------------\n",
    "    j'ai une liste de mots clés\n",
    "    je crée le pattern des mots clés\n",
    "    je recherche dans la colonne 'sms' si je trouve le pattern  \n",
    "    \"\"\"\n",
    "    mot_cles = ['URGENT!', 'Quiz!', 'YOU!', 'Txt:', 'now!', 'Call ', 'Win', 'WINNER', '!!', 'For sale', 'FREE!', 'PRIVATE!', 'Account', 'Latest News!']\n",
    "    pattern = re.compile(r\"(?=(\"+'|'.join(mot_cles)+r\"))\", re.IGNORECASE)\n",
    "    match = re.findall(pattern, sms)\n",
    "    return bool(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argent_posible (sms) :\n",
    "    \"\"\"\n",
    "    entrée : chaine de caractère\n",
    "    sortie : boolean\n",
    "    ---------------------\n",
    "    j'ai une liste de mots clés\n",
    "    je crée le pattern des mots clés\n",
    "    je recherche dans la colonne 'sms' si je trouve le pattern  \n",
    "    \"\"\"\n",
    "    mot_cles = ['£', '€', '\\$']\n",
    "    pattern = re.compile(r\"(?=(\"+'|'.join(mot_cles)+r\"))\", re.IGNORECASE)\n",
    "    match = re.findall(pattern, sms)\n",
    "    return bool(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def telephone_posible (sms) :\n",
    "    \"\"\"\n",
    "    entrée : chaine de carractère\n",
    "    sortie : boolean\n",
    "    ---------------------\n",
    "    crée le pattern des numero de tel\n",
    "    recherche dans une chaine de caractère si je trouve le pattern    \n",
    "    \"\"\"\n",
    "    pattern = re.compile(r\"(\\+\\d{1,3})?\\s?\\(?\\d{1,4}\\)?[\\s.-]?\\d{1,4}[\\s.-]?\\d{1,4}\")\n",
    "    match = re.search(pattern, sms)\n",
    "    return bool(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_posible (sms) :\n",
    "    \"\"\"\n",
    "    entrée : chaine de caractère\n",
    "    sortie : boolean\n",
    "    ---------------------\n",
    "    je crée le pattern des e-mails\n",
    "    je recherche dans la colonne 'sms' si je trouve le pattern    \n",
    "    \"\"\"\n",
    "    pattern = r\"([A-Za-z0-9]+[.-_])*[A-Za-z0-9]+@[A-Za-z0-9-]+(\\.[A-Z|a-z]{2,})+\"\n",
    "    match = re.findall(pattern, sms)\n",
    "    return bool(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lien_posible (sms) :\n",
    "    \"\"\"\n",
    "    entrée : chaine de caractère\n",
    "    sortie : boolean\n",
    "    ---------------------\n",
    "    j'ai une liste de mots clés\n",
    "    je crée le pattern des mots clés\n",
    "    je recherche dans la colonne 'sms' si je trouve le pattern  \n",
    "    \"\"\"\n",
    "    mot_cles = ['http', 'https', 'www.', 'click here']\n",
    "    pattern = re.compile(r\"(?=(\"+'|'.join(mot_cles)+r\"))\", re.IGNORECASE)\n",
    "    match = re.findall(pattern, sms)\n",
    "    return bool(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mot_maj_posible (sms) :\n",
    "    \"\"\"\n",
    "    entrée : chaine de caractère\n",
    "    sortie : boolean\n",
    "    ---------------------\n",
    "    je crée le pattern des majuscules\n",
    "    je recherche dans la colonne 'sms' si je trouve le pattern  \n",
    "    \"\"\"\n",
    "    pattern = \"[A-Z]{3}\"\n",
    "    match = re.findall(pattern, sms)\n",
    "    return bool(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_posible (sms) :\n",
    "    \"\"\"\n",
    "    entrée : chaine de caractère\n",
    "    sortie : int\n",
    "    ---------------------\n",
    "    je mesure la taille de chaque ligne de la colonne 'sms'\n",
    "    \"\"\"\n",
    "    return int(len(sms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_mot_posible (sms) :\n",
    "    \"\"\"\n",
    "    entrée : chaine de caractère\n",
    "    sortie : int\n",
    "    ---------------------\n",
    "    je mesure le nombre de mots de chaque ligne de la colonne 'sms'\n",
    "    \"\"\"\n",
    "    list_of_words = sms.split()\n",
    "    return int(len(list_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorisation_df (df) :\n",
    "    \"\"\"\n",
    "    entrée : un data frame\n",
    "    sortie : un data frame\n",
    "    ---------------------------\n",
    "    je crée la colonne 'mot_cles' grâce à la fonction 'mot_cle_posible'\n",
    "    je crée la colonne 'argent' grâce à la fonction 'argent_posible'\n",
    "    je crée la colonne 'telephone' grâce à la fonction 'telephone_posible'\n",
    "    je crée la colonne 'email' grâce à la fonction 'email_posible'\n",
    "    je crée la colonne 'lien' grâce à la fonction 'lien_posible'\n",
    "    je crée la colonne 'maj' grâce à la fonction 'mot_maj_posible'\n",
    "    je crée la colonne 'long' grâce à la fonction 'long_posible'\n",
    "    \"\"\"    \n",
    "    df['mot_cles'] = df['sms'].apply(mot_cle_posible)\n",
    "    df['argent'] = df['sms'].apply(argent_posible)\n",
    "    df['telephone'] = df['sms'].apply(telephone_posible)\n",
    "    df['email'] = df['sms'].apply(email_posible)\n",
    "    df['lien'] = df['sms'].apply(lien_posible)\n",
    "    df['maj'] = df['sms'].apply(mot_maj_posible)\n",
    "    df['long'] = df['sms'].apply(long_posible)\n",
    "    df['mot'] = df['sms'].apply(nb_mot_posible)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la fonction qui fait le pré-processing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_csv (model_pip, df_new) :\n",
    "    \"\"\"\n",
    "    -------------------------\n",
    "    \"\"\"\n",
    "    # prépare les données x et y pour le train_test_split\n",
    "    df_new_papel = taitement_na_duplic(df_new)\n",
    "    y_papel = df_new_papel['classification']\n",
    "    x_papel = df_new_papel['sms']\n",
    "\n",
    "    x_papel_df = x_papel.to_frame()\n",
    "    x_papel_vect = vectorisation_df(x_papel_df)\n",
    "\n",
    "    # x et y utilisé pour le train_test_split\n",
    "    x_new = x_papel_vect.drop('sms', axis=1)\n",
    "    y_new = LabelEncoder().fit_transform(y_papel)\n",
    "\n",
    "    # résultat de la pipeline\n",
    "    y_pred = model_pip.predict( x_new )\n",
    "    model_pip.score( x_new, y_new )\n",
    "\n",
    "    score = accuracy_score(y_new, y_pred)\n",
    "\n",
    "    return x_new, y_new, y_pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrainement_test(model_pip, x_train, x_test, y_train, y_test) :\n",
    "\n",
    "    # entrainement de la pipeline\n",
    "    model_pip.fit( x_train, y_train )\n",
    "\n",
    "    # résultat de la pipeline\n",
    "    y_pred = model_pip.predict( x_test )\n",
    "    model_pip.score( x_test, y_test )\n",
    "\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return model_pip, x_train, x_test, y_train, y_test, y_pred, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_IA ( df_init, model_parametre_init):\n",
    "\n",
    "    # enregistre les parametres d'entrée comme valeur de classe\n",
    "    df= df_init\n",
    "    model_parametre = model_parametre_init\n",
    "\n",
    "    # prépare les données x et y pour le train_test_split\n",
    "    df_papel = taitement_na_duplic(df)\n",
    "    y_papel = df_papel['classification']\n",
    "    x_papel = df_papel['sms']\n",
    "    x_papel_df = x_papel.to_frame()\n",
    "    x_papel_vect = vectorisation_df(x_papel_df)\n",
    "    \n",
    "    # x et y utilisé pour le train_test_split\n",
    "    x_papel_vect_2 = x_papel_vect.drop('sms', axis=1)\n",
    "    y_papel_encoder = LabelEncoder().fit_transform(y_papel)\n",
    "    \n",
    "    # train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split ( x_papel_vect_2, y_papel_encoder, train_size = 0.80, test_size = 0.20, random_state = 123 )\n",
    "\n",
    "    # Catégorise les colonnes de x pour le make_column_transformer\n",
    "    norm_num = ['long' , 'mot']\n",
    "    bool_one_hot = ['mot_cles','argent','telephone','email','lien','maj']\n",
    "    \n",
    "    # pipeline de transformation\n",
    "    one_hot_encoder_pip = make_pipeline ( OneHotEncoder() )\n",
    "    min_max_scaler_pip = make_pipeline ( MinMaxScaler () )\n",
    "    \n",
    "    # make_column_transformer\n",
    "    transform_colonne = make_column_transformer (( one_hot_encoder_pip, bool_one_hot ), \n",
    "                                                    ( min_max_scaler_pip, norm_num ))\n",
    "    \n",
    "    # pipeline principale\n",
    "    model_pip = make_pipeline(transform_colonne, model_parametre)\n",
    "\n",
    "    return model_pip, x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df =                     model                                          parametre  \\\n",
      "0            BernoulliNB  [{'name': 'alpha', 'describe': 'float or array...   \n",
      "1          CategoricalNB  [{'name': 'alpha', 'describe': 'float or array...   \n",
      "2           ComplementNB  [{'name': 'alpha', 'describe': 'float or array...   \n",
      "3             GaussianNB  [{'name': 'priors', 'describe': 'array-like of...   \n",
      "4          MultinomialNB  [{'name': 'alpha', 'describe': 'float or array...   \n",
      "5                    SVC  [{'name': 'C', 'describe': 'float,default=1.0'...   \n",
      "6                    SVR  [{'name': 'kernel', 'describe': '{linear,poly,...   \n",
      "7              LinearSVC  [{'name': 'penalty', 'describe': '{l1,l2},defa...   \n",
      "8              LinearSVR  [{'name': 'epsilon', 'describe': 'float,defaul...   \n",
      "9                  NuSVC  [{'name': 'nu', 'describe': 'float,default=0.5...   \n",
      "10                 NuSVR  [{'name': 'nu', 'describe': 'float,default=0.5...   \n",
      "11           OneClassSVM  [{'name': 'kernel', 'describe': '{linear,poly,...   \n",
      "12  KNeighborsClassifier  [{'name': 'n_neighbors', 'describe': 'int, def...   \n",
      "13                        [{'name': '', 'describe': '', 'type': '', 'def...   \n",
      "\n",
      "                                           param_grid  \n",
      "0   {'alpha': '0.0,0.1,0.5,1.0,5.0,10.0', 'force_a...  \n",
      "1   {'alpha': '0.0,0.1,0.5,1.0,5.0,10.0', 'force_a...  \n",
      "2   {'alpha': '0.0,0.1,0.5,1.0,5.0,10.0', 'force_a...  \n",
      "3                {'var_smoothing': '1e-9,1e-6,1e-12'}  \n",
      "4   {'alpha': '0.0,0.1,0.5,1.0,5.0,10.0', 'force_a...  \n",
      "5   {'C': '0.1,0.5,1.0,5.0,10.0', 'kernel': 'linea...  \n",
      "6   {'kernel': 'linear,poly,rbf', 'degree': '1,2,3...  \n",
      "7   {'penalty': 'l1,l2', 'loss': 'hinge,squared_hi...  \n",
      "8   {'epsilon': '0.001,0.01,0,1.0,10.0,100.0', 'C'...  \n",
      "9   {'nu': '0.0,0.001,0.01,0.1,1.0', 'kernel': 'li...  \n",
      "10  {'nu': '0.0,0.001,0.01,0.1,1.0', 'C': '0.1,0.5...  \n",
      "11  {'kernel': 'linear,poly,rbf', 'degree': '1,2,3...  \n",
      "12  {'n_neighbors': '1,2,3,4,5,6,7,8,9,10', 'weigh...  \n",
      "13                                                 {}  \n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# lien vers le json et csv\n",
    "####\n",
    "\n",
    "repertoir_fichier = os.path.dirname(os.path.abspath('briefs_spam_v3'))\n",
    "path_json = f\"{repertoir_fichier}\\\\model_parametre.json\"\n",
    "path_best_model = f\"{repertoir_fichier}\\\\best_model.csv\"\n",
    "\n",
    "####\n",
    "# ouverture des fichiers\n",
    "####\n",
    "\n",
    "# ouverture du fichier model_parametre.json\n",
    "df_json = pd.read_json(path_json, encoding = \"utf-8\", dtype=False)\n",
    "print(\"df = \", df_json)\n",
    "\n",
    "# ouverture du fichier SMSSpamCollection\n",
    "df_spam = pd.read_csv('https://raw.githubusercontent.com/remijul/dataset/master/SMSSpamCollection', \n",
    "                 sep='\\t',on_bad_lines='skip', header=None)\n",
    "\n",
    "# ouverture du fichier best_model.csv\n",
    "df_best_model = pd.read_csv(path_best_model, sep=',',on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CategoricalNB()\n",
    "model_pip, x_train, x_test, y_train, y_test = model_IA(df_spam, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [&#x27;mot_cles&#x27;, &#x27;argent&#x27;,\n",
       "                                                   &#x27;telephone&#x27;, &#x27;email&#x27;, &#x27;lien&#x27;,\n",
       "                                                   &#x27;maj&#x27;]),\n",
       "                                                 (&#x27;pipeline-2&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;long&#x27;, &#x27;mot&#x27;])])),\n",
       "                (&#x27;categoricalnb&#x27;, CategoricalNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [&#x27;mot_cles&#x27;, &#x27;argent&#x27;,\n",
       "                                                   &#x27;telephone&#x27;, &#x27;email&#x27;, &#x27;lien&#x27;,\n",
       "                                                   &#x27;maj&#x27;]),\n",
       "                                                 (&#x27;pipeline-2&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;minmaxscaler&#x27;,\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  [&#x27;long&#x27;, &#x27;mot&#x27;])])),\n",
       "                (&#x27;categoricalnb&#x27;, CategoricalNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;pipeline-1&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder())]),\n",
       "                                 [&#x27;mot_cles&#x27;, &#x27;argent&#x27;, &#x27;telephone&#x27;, &#x27;email&#x27;,\n",
       "                                  &#x27;lien&#x27;, &#x27;maj&#x27;]),\n",
       "                                (&#x27;pipeline-2&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;minmaxscaler&#x27;,\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 [&#x27;long&#x27;, &#x27;mot&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-1</label><div class=\"sk-toggleable__content\"><pre>[&#x27;mot_cles&#x27;, &#x27;argent&#x27;, &#x27;telephone&#x27;, &#x27;email&#x27;, &#x27;lien&#x27;, &#x27;maj&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline-2</label><div class=\"sk-toggleable__content\"><pre>[&#x27;long&#x27;, &#x27;mot&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalNB</label><div class=\"sk-toggleable__content\"><pre>CategoricalNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('onehotencoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['mot_cles', 'argent',\n",
       "                                                   'telephone', 'email', 'lien',\n",
       "                                                   'maj']),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('minmaxscaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['long', 'mot'])])),\n",
       "                ('categoricalnb', CategoricalNB())])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pip, x_train, x_test, y_train, y_test, y_pred, score = entrainement_test(model_pip, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9622823984526112"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[886,  25],\n",
       "       [ 14, 109]], dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 507, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 816, in transform\n",
      "    Xs = self._fit_transform(\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 933, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 689, in transform\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1016, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 199, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories [True] in column 3 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 507, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 816, in transform\n",
      "    Xs = self._fit_transform(\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 933, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 689, in transform\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1016, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 199, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories [True] in column 3 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 507, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 816, in transform\n",
      "    Xs = self._fit_transform(\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 933, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 689, in transform\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1016, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 199, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories [True] in column 3 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 507, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 816, in transform\n",
      "    Xs = self._fit_transform(\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 933, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 689, in transform\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1016, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 199, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories [True] in column 3 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 507, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 816, in transform\n",
      "    Xs = self._fit_transform(\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 933, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 689, in transform\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1016, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 199, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories [True] in column 3 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 507, in predict\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 816, in transform\n",
      "    Xs = self._fit_transform(\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 670, in _fit_transform\n",
      "    return Parallel(n_jobs=self.n_jobs)(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "                   ^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 933, in _transform_one\n",
      "    res = transformer.transform(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 689, in transform\n",
      "    Xt = transform.transform(Xt)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 1016, in transform\n",
      "    X_int, X_mask = self._transform(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\", line 199, in _transform\n",
      "    raise ValueError(msg)\n",
      "ValueError: Found unknown categories [True] in column 3 during transform\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 2 is out of bounds for axis 1 with size 2\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 2 is out of bounds for axis 1 with size 2\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 508, in predict\n",
      "    return self.steps[-1][1].predict(Xt, **predict_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 102, in predict\n",
      "    jll = self._joint_log_likelihood(X)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py\", line 1526, in _joint_log_likelihood\n",
      "    jll += self.feature_log_prob_[i][:, indices].T\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "IndexError: index 1 is out of bounds for axis 1 with size 1\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "N, train_score, val_score = learning_curve(model_pip, x_train, y_train, scoring='f1',\n",
    "                                            train_sizes=np.linspace(0.1, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pip_grid, x_train, x_test, y_train, y_test = model_IA(df_spam, SVC())\n",
    "choix_model = 'SVC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"C\": [0.1, 0.5, 1.0, 5.0, 10.0],\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "    \"degree\": [1, 2, 3, 4, 5],\n",
    "    \"gamma\": [\"auto\", \"scale\"],\n",
    "    \"max_iter\": [10, 100, 1000, 10000]\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 600 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'C' for estimator Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('pipeline-1',\n                                                  Pipeline(steps=[('onehotencoder',\n                                                                   OneHotEncoder())]),\n                                                  ['mot_cles', 'argent',\n                                                   'telephone', 'email', 'lien',\n                                                   'maj']),\n                                                 ('pipeline-2',\n                                                  Pipeline(steps=[('minmaxscaler',\n                                                                   MinMaxScaler())]),\n                                                  ['long', 'mot'])])),\n                ('svc', SVC())]). Valid parameters are: ['memory', 'steps', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 428, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 720, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 215, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 68, in _set_params\n    super().set_params(**params)\n  File \"c:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 229, in set_params\n    raise ValueError(\nValueError: Invalid parameter 'C' for estimator Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('pipeline-1',\n                                                  Pipeline(steps=[('onehotencoder',\n                                                                   OneHotEncoder())]),\n                                                  ['mot_cles', 'argent',\n                                                   'telephone', 'email', 'lien',\n                                                   'maj']),\n                                                 ('pipeline-2',\n                                                  Pipeline(steps=[('minmaxscaler',\n                                                                   MinMaxScaler())]),\n                                                  ['long', 'mot'])])),\n                ('svc', SVC())]). Valid parameters are: ['memory', 'steps', 'verbose'].\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[182], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(model_pip_grid, param_grid\u001b[38;5;241m=\u001b[39mparams, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m model_grid\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32mc:\\Users\\sandy\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'C' for estimator Pipeline(steps=[('columntransformer',\n                 ColumnTransformer(transformers=[('pipeline-1',\n                                                  Pipeline(steps=[('onehotencoder',\n                                                                   OneHotEncoder())]),\n                                                  ['mot_cles', 'argent',\n                                                   'telephone', 'email', 'lien',\n                                                   'maj']),\n                                                 ('pipeline-2',\n                                                  Pipeline(steps=[('minmaxscaler',\n                                                                   MinMaxScaler())]),\n                                                  ['long', 'mot'])])),\n                ('svc', SVC())]). Valid parameters are: ['memory', 'steps', 'verbose']."
     ]
    }
   ],
   "source": [
    "model_grid = GridSearchCV(model_pip_grid, param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
    "model_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Best_Parameters \u001b[38;5;241m=\u001b[39m model_grid\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m      2\u001b[0m Best_Accuracy \u001b[38;5;241m=\u001b[39m model_grid\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "Best_Parameters = model_grid.best_params_\n",
    "Best_Accuracy = model_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Best_Parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Best_Parameters\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Best_Parameters' is not defined"
     ]
    }
   ],
   "source": [
    "Best_Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Best_Accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Best_Accuracy\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Best_Accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "Best_Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste avec un nouveau sms :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detetion_de_spam(sms) :\n",
    "    \n",
    "    x = np.array([sms]).reshape(1, 1)\n",
    "\n",
    "    # prépare les données x et y pour le train_test_split\n",
    "    x_papel = x\n",
    "\n",
    "    x_papel_df = pd.DataFrame(x_papel, columns=['sms'])\n",
    "    x_papel_vect = vectorisation_df(x_papel_df)\n",
    "\n",
    "    # x et y utilisé pour le train_test_split\n",
    "    x_new = x_papel_vect.drop('sms', axis=1)\n",
    "\n",
    "    # résultat de la pipeline\n",
    "    y_pred = model_pip.predict( x_new )\n",
    "    y_pred_proba = model_pip.predict_proba( x_new )\n",
    "\n",
    "    return y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste 1 : ham = \"Thanx 4 2day! U r a goodmate I THINK UR RITE SARY! ASUSUAL!1 U CHEERED ME UP! LOVE U FRANYxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham détecté avec 98.07 % de chance d'être vrai\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_proba = detetion_de_spam(\"Thanx 4 2day! U r a goodmate I THINK UR RITE SARY! ASUSUAL!1 U CHEERED ME UP! LOVE U FRANYxxxxx\")\n",
    "pourcent_ham = round( (y_pred_proba[0][0]*100) , 2)\n",
    "pourcent_spam = round( (y_pred_proba[0][1]*100) , 2)\n",
    "\n",
    "if y_pred == 0 :\n",
    "    print(f\"ham détecté avec {pourcent_ham} % de chance d'être vrai\")\n",
    "else :\n",
    "    print(f\"spam détecté avec {pourcent_spam} % de chance d'être vrai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teste 2 : spam = \"Refused a loan? Secured or Unsecured? Can't get credit? Call free now 0800 195 6669 or text back 'help' & we will!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam détecté avec 99.92 % de chance d'être vrai\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_pred_proba = detetion_de_spam(\"Refused a loan? Secured or Unsecured? Can't get credit? Call free now 0800 195 6669 or text back 'help' & we will!\")\n",
    "pourcent_ham = round( (y_pred_proba[0][0]*100) , 2)\n",
    "pourcent_spam = round( (y_pred_proba[0][1]*100) , 2)\n",
    "\n",
    "if y_pred == 0 :\n",
    "    print(f\"ham détecté avec {pourcent_ham} % de chance d'être vrai\")\n",
    "else :\n",
    "    print(f\"spam détecté avec {pourcent_spam} % de chance d'être vrai\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
